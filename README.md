#  Clasificaci贸n de Emociones en Tweets con ML y Deep Learning

Este proyecto implementa y compara **tres enfoques diferentes** de clasificaci贸n de emociones en tweets:  
1. **Regresi贸n Log铆stica (TF-IDF)**  
2. **Red LSTM (Embeddings + Secuencias)**  
3. **Fine-tuning de BERT Multilingual**  

El objetivo es identificar correctamente emociones como *alegr铆a, tristeza, miedo, ira, sorpresa, disgusto, otros*, y analizar el desempe帽o de cada modelo en diferentes eventos.

---

## И Modelos Implementados

###  Modelo 1: Logistic Regression (Baseline)
- **Representaci贸n:** TF-IDF (1-2 ngramas, `max_features=5000`)
- **Algoritmo:** `LogisticRegression(max_iter=500)`
- **M茅tricas:** Accuracy, Precision, Recall, F1-score
- **Ventaja:** r谩pido de entrenar, sirve como referencia.

---

###  Modelo 2: LSTM
- **Representaci贸n:** Embeddings trainables + Secuencias
- **Arquitectura:**
  - `Embedding(10000, 128)`
  - `LSTM(128, dropout=0.2, recurrent_dropout=0.2)`
  - `Dense(num_classes, softmax)`
- **Entrenamiento:** 5 茅pocas, `batch_size=64`
- **M茅tricas:** igual que el modelo baseline.
- **Ventaja:** aprende dependencias secuenciales en el texto.

---

###  Modelo 3: BERT (Transformers)
- **Pre-entrenamiento:** `bert-base-multilingual-cased`
- **Fine-tuning:** con nuestro dataset
- **Representaci贸n:** contextual de palabras
- **Entrenamiento:** con GPU (Colab recomendado)
- **Ventaja:** mejor desempe帽o esperado en clasificaci贸n de texto.


---
##  C贸mo Ejecutar

Corre el Notebook sin preocipaciones de **subir archivos**: la data se **lee directamente desde GitHub**.
